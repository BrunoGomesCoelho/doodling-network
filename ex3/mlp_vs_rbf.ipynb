{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ilNq9sScQLHR"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, log_loss\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "TESTING = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classe que representa uma MLP\n",
    "\n",
    "Implementado de uma maneira vetorizada por mini batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     28,
     39,
     47,
     56,
     104
    ]
   },
   "outputs": [],
   "source": [
    "class MLP(): \n",
    "    def __init__(self, dimensions=[], momentum=0.9, classification=True, \n",
    "                 lr=0.1, testing=False, use_relu=False):\n",
    "        self.lr = lr\n",
    "        self.velocities = []\n",
    "        self.momentum = momentum\n",
    "        self.classification = classification\n",
    "        \n",
    "        # Initialize fully connected layers\n",
    "        self.layers = []\n",
    "        for idx, (input_dim, output_dim) in enumerate(dimensions, 1):\n",
    "            self.layers.append(self.Linear(input_dim, output_dim))\n",
    "            # For each linear layer, add a velocity term starting at 0\n",
    "            self.velocities.append(np.zeros((input_dim, output_dim)))\n",
    "            if idx != len(dimensions):\n",
    "                if use_relu:\n",
    "                    self.layers.append(self.ReLU())\n",
    "                else:\n",
    "                    self.layers.append(self.Sigmoid())\n",
    "            else: # Last layer\n",
    "                if self.classification:\n",
    "                    self.layers.append(self.Softmax()) # for the last use softmax\n",
    "            \n",
    "        if classification:\n",
    "            self.cost = self.CrossEntropy()\n",
    "        else:\n",
    "            self.cost = self.SquareLoss()\n",
    "        \n",
    "    class Sigmoid():\n",
    "        def forward(self, x):\n",
    "            # Cip the sigmoid to avoid overflow\n",
    "            # See https://stackoverflow.com/questions/23128401/overflow-error-in-neural-networks-implementation\n",
    "            clipped_x = np.clip(x, -500, 500)\n",
    "            self.old_y = np.exp(clipped_x) / (1. + np.exp(clipped_x))\n",
    "            return self.old_y\n",
    "\n",
    "        def backward(self, grad):\n",
    "            return self.old_y * (1. - self.old_y) * grad\n",
    "\n",
    "    class Softmax():\n",
    "        def forward(self,x):\n",
    "            self.old_y = np.exp(x) / np.exp(x).sum(axis=1) [:,None]\n",
    "            return self.old_y\n",
    "\n",
    "        def backward(self,grad):\n",
    "            return self.old_y * (grad -(grad * self.old_y).sum(axis=1)[:,None])\n",
    "\n",
    "    class CrossEntropy():\n",
    "        def forward(self,x,y):\n",
    "            self.old_x = x.clip(min=1e-8,max=None)\n",
    "            self.old_y = y\n",
    "            return (np.where(y==1,-np.log(self.old_x), 0)).sum(axis=1)\n",
    "\n",
    "        def backward(self):\n",
    "            return np.where(self.old_y==1,-1/self.old_x, 0)\n",
    "    \n",
    "    class Linear():\n",
    "        def __init__(self,n_in,n_out):\n",
    "            self.weights = np.random.randn(n_in,n_out) * np.sqrt(2/n_in)\n",
    "            self.biases = np.zeros(n_out)\n",
    "\n",
    "            self.w_vel = np.zeros((n_in,n_out))\n",
    "            self.b_vel = np.zeros(n_out)\n",
    "\n",
    "        def update_velocity(self, w_vel, b_vel):\n",
    "            self.w_vel = w_vel\n",
    "            self.b_vel = b_vel\n",
    "\n",
    "        def forward(self, x):\n",
    "            self.old_x = x\n",
    "            return np.dot(x,self.weights) + self.biases\n",
    "\n",
    "        def backward(self,grad):\n",
    "            self.grad_b = grad.mean(axis=0)\n",
    "            self.grad_w = (np.matmul(self.old_x[:,:,None],grad[:,None,:])).mean(axis=0)\n",
    "            return np.dot(grad,self.weights.transpose())\n",
    "\n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self,x,y):\n",
    "        return self.cost.forward(self.forward(x),y)\n",
    "\n",
    "    def backward(self):\n",
    "        grad = self.cost.backward()\n",
    "        for i in range(len(self.layers)-1,-1,-1):\n",
    "            grad = self.layers[i].backward(grad)\n",
    "            \n",
    "    def fit(self, x, y, n_iter=100, mini_batch=32):\n",
    "        for _ in range(n_iter):   \n",
    "            total_loss = 0\n",
    "            for start_idx in range(0, len(x), mini_batch):\n",
    "                x_batch = x[start_idx:start_idx+mini_batch]\n",
    "                y_batch = y[start_idx:start_idx+mini_batch]   \n",
    "                \n",
    "                # Forward and backward\n",
    "                loss = self.loss(x_batch,y_batch)\n",
    "                total_loss += loss.sum()\n",
    "                self.backward()\n",
    "                \n",
    "                # Update according to momentum\n",
    "                for layer in self.layers:\n",
    "                    if type(layer) == self.Linear:\n",
    "                        new_w_vel = self.momentum*layer.w_vel - self.lr*layer.grad_w\n",
    "                        new_b_vel = self.momentum*layer.b_vel - self.lr*layer.grad_b\n",
    "                        \n",
    "                        layer.weights += new_w_vel\n",
    "                        layer.weights += new_b_vel\n",
    "                        \n",
    "                        layer.update_velocity(new_w_vel, new_b_vel)\n",
    "\n",
    "    def predict(self, x):\n",
    "        output = self.forward(x)\n",
    "        if self.classification:\n",
    "            return output.argmax(axis=-1)                       \n",
    "        else:\n",
    "            return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classe que representa uma RBF\n",
    "\n",
    "Implementado de uma maneira vetorizada por mini batch. \n",
    "\n",
    "Primeiro vamos definir as diversas funções de RBF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(X, centroid, sigma=None):\n",
    "    norm = np.linalg.norm(X-centroid, axis=1)\n",
    "    mult = -1 / (2*sigma**2)\n",
    "    return np.exp(mult*norm**2)\n",
    "    \n",
    "def multi_square(X, centroid, sigma):\n",
    "    norm = np.linalg.norm(X-centroid, axis=1)\n",
    "    return np.sqrt(sigma**2 + norm**2)\n",
    "\n",
    "def thin_plate_spline(X, centroid, sigma):\n",
    "    norm = np.linalg.norm(X-centroid, axis=1)\n",
    "    return norm*norm*np.log(norm[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora sim a nossa RBF que chama uma Adalaide simples por trás:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class RBF(): \n",
    "    def __init__(self, rbf, input_size=3, output_size=3, lr=0.1, \n",
    "                 testing=False):\n",
    "        self.lr = lr\n",
    "        self.mlp = MLP(dimensions=[(input_size, output_size)], momentum=0,\n",
    "                      classification=True, lr=lr, testing=testing)\n",
    "        \n",
    "        # Initialize fully connected layers\n",
    "        self.centroids = None\n",
    "        self.rbf = rbf\n",
    "           \n",
    "    def calculate_sigma(self):\n",
    "        \"\"\"Calculate sigma according to:  sigma = Dmax / sqrt(2*K)\n",
    "        where Dmax is the maximum dist between centroids and K the number of centroids\n",
    "        \"\"\"\n",
    "        D_max = 0\n",
    "        for idx, group1 in enumerate(self.centroids):\n",
    "            for group2 in self.centroids[idx+1:]:\n",
    "                dist = np.linalg.norm(group1-group2)\n",
    "                if dist > D_max:\n",
    "                    D_max = dist\n",
    "        return D_max / np.sqrt(2*len(self.centroids))\n",
    "        \n",
    "    def rbf_layer(self, x):\n",
    "        \"\"\"Converts our x matrix, where each row is a example and each column a feature,\n",
    "        into a new matrix where each row is a example and each columm a\n",
    "        RBF function with a different centroid.\"\"\"\n",
    "        new_x = np.zeros((x.shape[0], len(self.centroids)))\n",
    "        \n",
    "        for idx, centroid in self.centroids.iterrows():\n",
    "            new_x[:, idx-1] = self.rbf(x, centroid, self.sigma)\n",
    "        return new_x\n",
    "\n",
    "    def fit(self, x, y, n_iter=100, mini_batch=32):\n",
    "        # Calculate the centroids and sigma\n",
    "        self.centroids = x.groupby(y).mean()\n",
    "        self.sigma = self.calculate_sigma()\n",
    "        \n",
    "        # Go through the RBF layer\n",
    "        new_x = self.rbf_layer(x)\n",
    "        new_y = pd.get_dummies(y).values\n",
    "        \n",
    "        # Call the 1 layer MLP\n",
    "        self.mlp.fit(new_x, new_y, n_iter=n_iter)\n",
    "                \n",
    "    def predict(self, x):\n",
    "        new_x = self.rbf_layer(x)\n",
    "        output = self.mlp.forward(new_x)\n",
    "        return output.argmax(axis=-1)                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- - - \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções auxiliares\n",
    "\n",
    "Diversas funções que seram utilizadas para ambos os datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para carregar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def load_and_analyze(filename, target, header=0):\n",
    "    df = pd.read_csv(filename, header=header)\n",
    "    # Check for nulls\n",
    "    print(f\"Temos {df.isna().sum().sum()} nulos na nossa tabela\")\n",
    "    \n",
    "    x = df.drop(columns=[target])\n",
    "    y = df[target] - 1\n",
    "    sns.countplot(y)\n",
    "    plt.show()\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temos 0 nulos na nossa tabela\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = load_and_analyze(\"wine.data\", target=0, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função  para normalizar os dados que vamos utilizar posteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(x_train, x_test, y=None, pandas=True):\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    x_train_norm = scaler.fit_transform(x_train)\n",
    "    x_test_norm = scaler.transform(x_test)\n",
    "    x_train_norm, x_test_norm = [pd.DataFrame(x) for x in (x_train_norm, x_test_norm)]\n",
    "    \n",
    "    return x_train_norm, x_test_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para rodar 1 experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def run_experiment(x, y, model, test_percent=0.3, n_iter=100, mlp=False):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Process our data and normalize\n",
    "    if mlp:\n",
    "        new_y = pd.get_dummies(y)\n",
    "    else:\n",
    "        new_y = y\n",
    "        \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, new_y, stratify=y, \n",
    "                                                       test_size=test_percent)\n",
    "    x_train, x_test = normalize_data(x_train, x_test, pandas=True)\n",
    "\n",
    "    # Train and evaluate\n",
    "    if mlp:\n",
    "        model.fit(x_train.values, y_train.values, n_iter=n_iter)\n",
    "    else:\n",
    "        model.fit(x_train, y_train.values, n_iter=n_iter)\n",
    "    preds = model.predict(x_test)\n",
    "    \n",
    "    if mlp:\n",
    "        score = accuracy_score(y_test.values.argmax(axis=-1), preds)\n",
    "    else:\n",
    "        score = accuracy_score(y_test, preds)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    return score, end_time-start_time\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roda todos os nossos experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Nome\", \"Acurácia\", \"Tempo\"]\n",
    "results = pd.DataFrame(columns=cols)\n",
    "\n",
    "models = {\n",
    "    \"RBF-G\": RBF(gaussian),\n",
    "    \"RBF-MQ\": RBF(multi_square),\n",
    "    \"RBF-TPS\": RBF(thin_plate_spline),\n",
    "    \"MLP-0\": MLP(dimensions=[(13, 3)], momentum=0, lr=0.1),\n",
    "    \"MLP-1\": MLP(dimensions=[(13, 32), (32, 3)], momentum=0, lr=0.1),\n",
    "    \"MLP-2\": MLP(dimensions=[(13, 16), (16, 8), (8, 3)], momentum=0, lr=0.1),\n",
    "}\n",
    "is_mlp = [False]*3 + [True]*3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10000\n",
    "for (name, model), mlp in zip(models.items(), is_mlp):\n",
    "    score, runtime = run_experiment(x, y, model, n_iter=n_iter, mlp=mlp)\n",
    "    results.loc[(len(results))] = (name, score, runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nome</th>\n",
       "      <th>Acurácia</th>\n",
       "      <th>Tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RBF-G</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>6.731686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RBF-MQ</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>6.570518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RBF-TPS</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>6.584831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP-0</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>7.062049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP-1</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>14.926985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP-2</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>17.974810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Nome  Acurácia      Tempo\n",
       "0    RBF-G  0.962963   6.731686\n",
       "1   RBF-MQ  0.981481   6.570518\n",
       "2  RBF-TPS  0.685185   6.584831\n",
       "3    MLP-0  0.648148   7.062049\n",
       "4    MLP-1  0.833333  14.926985\n",
       "5    MLP-2  0.814815  17.974810"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF-G\t96.30%\t6.73s\n",
      "RBF-MQ\t98.15%\t6.57s\n",
      "RBF-TPS\t68.52%\t6.58s\n",
      "MLP-0\t64.81%\t7.06s\n",
      "MLP-1\t83.33%\t14.93s\n",
      "MLP-2\t81.48%\t17.97s\n"
     ]
    }
   ],
   "source": [
    "# Format the data to be generated in our report, using https://www.tablesgenerator.com/\n",
    "for index, data in results.iterrows():\n",
    "    name, acc, runtime = data \n",
    "    print(f\"{name}\\t{100*acc:.2f}%\\t{runtime:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os melhores resultados em termo de acurácia foram obtidos para os dois modelos RBFs, com a função gaussiana ou a função multi quadrática. Eles obtiveram resultados significativamente melhores que a MLP-1 ou a MLP-2, os próximos colocados na classificação. \n",
    "\n",
    "Além disso, vale ressaltar que os modelos RBF foram 50\\% mais rápidos que as MLP com no mínimo 1 camada escondida (MLP-1 e MLP-2). \n",
    "\n",
    "\n",
    "Em conclusão, com esse trabalho aprendemos mais profundamente sobre o funcionamento de uma rede RBF e mostramos que seu uso pode ser uma alternativa válida para problemas de classificação, tanto pelo seu desempenho alto como pelo seu menor tempo de exucação em comparação com redes com 1 ou mais camadas escondidas."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "adaline.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
